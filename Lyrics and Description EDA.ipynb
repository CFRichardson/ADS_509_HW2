{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "uF0yNrzyU0xG",
   "metadata": {
    "id": "uF0yNrzyU0xG",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Chris Richardson <br><br>\n",
    "\n",
    "Sep 18, 2022 <br><br>\n",
    "\n",
    "ADS-509-Fall <br><br>\n",
    "\n",
    "Github Link: [https://github.com/CFRichardson/USD_ADS_509_HW2](https://github.com/CFRichardson/ADS_509_HW2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QTY_iykaU0xH",
   "metadata": {
    "id": "QTY_iykaU0xH",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h1> ADS 509 Assignment 2.1: Tokenization, Normalization, Descriptive Statistics</h1>\n",
    "\n",
    "In the previous assignment you put together Twitter data and lyrics data on two artists. In this assignment we explore some of the textual features of those data sets. If, for some reason, you did not complete that previous assignment, data to use for this assignment can be found in the assignment materials section of Blackboard. \n",
    "\n",
    "This assignment asks you to write a short function to calculate some descriptive statistics on a piece of text. Then you are asked to find some interesting and unique statistics on your corpora. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f79baf9",
   "metadata": {
    "id": "7f79baf9",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h1> ADS 509 Assignment 2.1: Tokenization, Normalization, Descriptive Statistics</h1>\n",
    "\n",
    "In the previous assignment you put together Twitter data and lyrics data on two artists. In this assignment we explore some of the textual features of those data sets. If, for some reason, you did not complete that previous assignment, data to use for this assignment can be found in the assignment materials section of Blackboard. \n",
    "\n",
    "This assignment asks you to write a short function to calculate some descriptive statistics on a piece of text. Then you are asked to find some interesting and unique statistics on your corpora. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4YbY5PeIKvX2",
   "metadata": {
    "id": "4YbY5PeIKvX2",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2d096b7",
   "metadata": {
    "id": "e2d096b7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import emoji\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "sw = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ZWzrI08wKvX4",
   "metadata": {
    "id": "ZWzrI08wKvX4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "def null_ratio(dataframe):\n",
    "    return dataframe.isnull().mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "923b5a86",
   "metadata": {
    "id": "923b5a86",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "twitter_folder = 'wk2/ADS_509_HW2/ADS_509_HW2/twitter'\n",
    "lyrics_folder = 'wk2/ADS_509_HW2/ADS_509_HW2/lyrics'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0HJr8GuGKvX5",
   "metadata": {
    "id": "0HJr8GuGKvX5",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Descriptive Stats FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "qLvuwYIIKvX5",
   "metadata": {
    "id": "qLvuwYIIKvX5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def descriptive_stats(tokens, top_tokens=False, num_top_tokens = 5, verbose=False) :\n",
    "    \"\"\"\n",
    "        Given a list of tokens, print number of tokens, number of unique tokens,\n",
    "        number of characters, lexical diversity (https://en.wikipedia.org/wiki/Lexical_diversity),\n",
    "        and num_tokens most common tokens. Return a list with the number of tokens, number\n",
    "        of unique tokens, lexical diversity, and number of characters.\n",
    "    \"\"\"\n",
    "    def character_counter(text):\n",
    "        total_chars = 0\n",
    "        for word in text:\n",
    "            total_chars += len(word)\n",
    "        return total_chars\n",
    "\n",
    "    # Fill in the correct values here.\n",
    "    num_tokens = len(tokens)\n",
    "    num_unique_tokens = len(set(tokens))\n",
    "    lexical_diversity = num_unique_tokens / num_tokens\n",
    "    num_characters = character_counter(tokens)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"There are {num_tokens} tokens in the data.\")\n",
    "        print(f\"There are {num_unique_tokens} unique tokens in the data.\")\n",
    "        print(f\"There are {num_characters} characters in the data.\")\n",
    "        print(f\"The lexical diversity is {lexical_diversity:.3f} in the data.\")\n",
    "\n",
    "    # print the five most common tokens\n",
    "    if top_tokens:\n",
    "        most_common = Counter(tokens).most_common(num_top_tokens)\n",
    "        keys = [x[0] for x in most_common]\n",
    "        values = [x[1] for x in most_common]\n",
    "\n",
    "        print('**'*12, '\\n', f'-----TOP {num_top_tokens} TOKENS-----')\n",
    "        print(pd.DataFrame({'keys':keys, 'values':values}))\n",
    "\n",
    "    return([num_tokens, num_unique_tokens,\n",
    "            lexical_diversity,\n",
    "            num_characters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59dcf058",
   "metadata": {
    "id": "59dcf058",
    "outputId": "1af05e09-3a9c-46d2-d214-3dcb09f3b50c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13 tokens in the data.\n",
      "There are 9 unique tokens in the data.\n",
      "There are 55 characters in the data.\n",
      "The lexical diversity is 0.692 in the data.\n",
      "************************ \n",
      " -----TOP 5 TOKENS-----\n",
      "      keys  values\n",
      "0     text       3\n",
      "1     here       2\n",
      "2  example       2\n",
      "3       is       1\n",
      "4     some       1\n"
     ]
    }
   ],
   "source": [
    "text = \"here is some example text with other example text here in this text\".split()\n",
    "assert(descriptive_stats(text, top_tokens=True, verbose=True)[0] == 13)\n",
    "assert(descriptive_stats(text)[1] == 9)\n",
    "assert(abs(descriptive_stats(text)[2] - 0.69) < 0.02)\n",
    "assert(descriptive_stats(text)[3] == 55)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e7e1a2",
   "metadata": {
    "id": "d2e7e1a2",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Q: Why is it beneficial to use assertion statements in your code?\n",
    "\n",
    "A:  Similar yet different to an \"If True\" statement, assertions check if the provided statement within the parentheses is True; if statement is false an AssertionError is thrown and the kernel will stop running."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3bf93e",
   "metadata": {
    "id": "9d3bf93e",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data Input\n",
    "\n",
    "Now read in each of the corpora. For the lyrics data, it may be convenient to store the entire contents of the file to make it easier to inspect the titles individually, as you'll do in the last part of the assignment. In the solution, I stored the lyrics data in a dictionary with two dimensions of keys: artist and song. The value was the file contents. A data frame would work equally well. \n",
    "\n",
    "For the Twitter data, we only need the description field for this assignment. Feel free all the descriptions read it into a data structure. In the solution, I stored the descriptions as a dictionary of lists, with the key being the artist. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cr8HHtjJKvX8",
   "metadata": {
    "id": "cr8HHtjJKvX8",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Read in Lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37d70801",
   "metadata": {
    "id": "37d70801",
    "outputId": "735f91df-cecb-41b2-b43f-8c81c4e8e21e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  Artist                Title  \\\n0   FFDP                Ashes   \n1   FFDP  The_Way_Of_The_Fist   \n2   FFDP            Salvation   \n\n                                              Lyrics  \n0     Right Hate, hate, hate! Bring it!  You don'...  \n1     Break this shit down! Zoltan, open the sky!...  \n2     Disgusted by your weakness You have no righ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Artist</th>\n      <th>Title</th>\n      <th>Lyrics</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>FFDP</td>\n      <td>Ashes</td>\n      <td>Right Hate, hate, hate! Bring it!  You don'...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>FFDP</td>\n      <td>The_Way_Of_The_Fist</td>\n      <td>Break this shit down! Zoltan, open the sky!...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>FFDP</td>\n      <td>Salvation</td>\n      <td>Disgusted by your weakness You have no righ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd = '/Volumes/GoogleDrive/My Drive/_509/wk2/ADS_509_HW2/'\n",
    "\n",
    "# Read in the lyrics data\n",
    "ffdp_path = 'lyrics/FFDP/FFDP_song_lyrics_df.csv'\n",
    "ffdp_lyrics_df = pd.read_csv(cwd + ffdp_path)\n",
    "ffdp_lyrics_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "C1OOectCKvX9",
   "metadata": {
    "id": "C1OOectCKvX9",
    "outputId": "83ec48ca-9679-4b0b-9718-92ad38481c6c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         Artist       Title                                             Lyrics\n0  OfficialRezz        Lost     What a beautiful world to be anything but a...\n1  OfficialRezz  Melancholy     All these thoughts are running through my h...\n2  OfficialRezz       Relax     Just take a nice breath in. Exhale the brea...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Artist</th>\n      <th>Title</th>\n      <th>Lyrics</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>OfficialRezz</td>\n      <td>Lost</td>\n      <td>What a beautiful world to be anything but a...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>OfficialRezz</td>\n      <td>Melancholy</td>\n      <td>All these thoughts are running through my h...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>OfficialRezz</td>\n      <td>Relax</td>\n      <td>Just take a nice breath in. Exhale the brea...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rezz_path = 'lyrics/OfficialRezz/OfficialRezz_song_lyrics_df.csv'\n",
    "rezz_lyrics_df = pd.read_csv(cwd + rezz_path)\n",
    "rezz_lyrics_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iXw2mHdoKvX9",
   "metadata": {
    "id": "iXw2mHdoKvX9",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Read in Twitter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "-mDYS7jpKvX9",
   "metadata": {
    "id": "-mDYS7jpKvX9",
    "outputId": "6a1b3b25-fa67-4008-a65c-56e9f84bd242",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  Artist                                        Description\n0   FFDP                                                NaN\n1   FFDP  A pup who loves to boop the snoot! | 27 | Pans...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Artist</th>\n      <th>Description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>FFDP</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>FFDP</td>\n      <td>A pup who loves to boop the snoot! | 27 | Pans...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Read in the twitter data\n",
    "ffdp_path = 'twitter/FFDP_followers_data.txt'\n",
    "ffdp_followers_df = pd.read_csv(cwd + ffdp_path, sep='\\t', engine='python')\n",
    "ffdp_followers_df = ffdp_followers_df[['Artist', 'Description']]\n",
    "ffdp_followers_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "debcac5a",
   "metadata": {
    "id": "debcac5a",
    "outputId": "336740eb-93b9-4fd5-d234-b6e2db91b251",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         Artist   Description\n0  OfficialRezz  CRUZIN’ 🥺❤️💡\n1  OfficialRezz           NaN",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Artist</th>\n      <th>Description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>OfficialRezz</td>\n      <td>CRUZIN’ 🥺❤️💡</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>OfficialRezz</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rezz_path = 'twitter/OfficialRezz_followers_data.txt'\n",
    "rezz_followers_df = pd.read_csv(cwd + rezz_path, sep='\\t', engine='python')\n",
    "rezz_followers_df = rezz_followers_df[['Artist', 'Description']]\n",
    "rezz_followers_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GkRtXsALKvX-",
   "metadata": {
    "id": "GkRtXsALKvX-",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As we see, some descriptions are sadly NaNs.  Let's check out the % of NaNs in each df."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZsTUMvvbUAZh",
   "metadata": {
    "id": "ZsTUMvvbUAZh",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Twitter Description Null %"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wkaPZZMZUAZh",
   "metadata": {
    "id": "wkaPZZMZUAZh",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### FFDP Null %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "_g3v0BuhKvX-",
   "metadata": {
    "id": "_g3v0BuhKvX-",
    "outputId": "35628e50-214a-4450-daf7-873f3a8cc582",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Artist          0.000000\nDescription    40.418404\ndtype: float64"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_ratio(ffdp_followers_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eF67NCHVUAZi",
   "metadata": {
    "id": "eF67NCHVUAZi",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Rezz Null %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fpKF2swFKvX-",
   "metadata": {
    "id": "fpKF2swFKvX-",
    "outputId": "976a1308-7fd8-4fb5-fb86-1bc316f86139",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Artist          0.000000\nDescription    26.866269\ndtype: float64"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_ratio(rezz_followers_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CrOwd1r5UAZi",
   "metadata": {
    "id": "CrOwd1r5UAZi",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## NA Row Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "uVx-QmDEKvX_",
   "metadata": {
    "id": "uVx-QmDEKvX_",
    "outputId": "f00216c8-094d-44a5-aa03-469ea95031f9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 59,581 rows left for FFDP after NaN removal.\n",
      "There are 73,133 rows for Rezz left after NaN removal.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Artist         0.0\nDescription    0.0\ndtype: float64"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffdp_followers_df = ffdp_followers_df.dropna().reset_index(drop=True)\n",
    "\n",
    "rezz_followers_df = rezz_followers_df.dropna().reset_index(drop=True)\n",
    "print(f'There are {ffdp_followers_df.shape[0]:,} rows left for FFDP after NaN removal.')\n",
    "print(f'There are {rezz_followers_df.shape[0]:,} rows for Rezz left after NaN removal.')\n",
    "\n",
    "# sanity check\n",
    "null_ratio(ffdp_followers_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5f3b12",
   "metadata": {
    "id": "6a5f3b12",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data Cleaning\n",
    "\n",
    "Now clean and tokenize your data. Remove punctuation chacters (available in the `punctuation` object in the `string` library), split on whitespace, fold to lowercase, and remove stopwords. Store your cleaned data, which must be accessible as an interable for `descriptive_stats`, in new objects or in new columns in your data frame. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "Pk2Ng3p_KvX_",
   "metadata": {
    "id": "Pk2Ng3p_KvX_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def text_prep(text):\n",
    "    punctuation = set(string.punctuation) # speeds up comparison\n",
    "    # remove punctuation chars then tokenize string\n",
    "    text = ''.join(char for char in text if char not in punctuation).split()\n",
    "    # lowercase all\n",
    "    text = [word.lower() for word in text]\n",
    "    # remove stop words\n",
    "    text = [word for word in text if word not in sw]\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "RUkj-gpTKvX_",
   "metadata": {
    "id": "RUkj-gpTKvX_",
    "outputId": "c4c0e074-5fd1-4c3f-85e1-0f5986b44843",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         Artist                                        Description  \\\n0  OfficialRezz                                       CRUZIN’ 🥺❤️💡   \n1  OfficialRezz  @__SoCalTxOwl93  💙🦉 I'm Mr American Dream sinc...   \n\n                                        Cleaned_Desc  \n0                                    [cruzin’, 🥺❤️💡]  \n1  [socaltxowl93, 💙🦉, im, mr, american, dream, si...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Artist</th>\n      <th>Description</th>\n      <th>Cleaned_Desc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>OfficialRezz</td>\n      <td>CRUZIN’ 🥺❤️💡</td>\n      <td>[cruzin’, 🥺❤️💡]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>OfficialRezz</td>\n      <td>@__SoCalTxOwl93  💙🦉 I'm Mr American Dream sinc...</td>\n      <td>[socaltxowl93, 💙🦉, im, mr, american, dream, si...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffdp_followers_df['Cleaned_Desc'] = ffdp_followers_df.loc[:,'Description'].map(text_prep)\n",
    "\n",
    "rezz_followers_df['Cleaned_Desc'] = rezz_followers_df.loc[:,'Description'].map(text_prep)\n",
    "rezz_followers_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eZHMrs7DKvYA",
   "metadata": {
    "id": "eZHMrs7DKvYA",
    "outputId": "5ec1365f-b187-4b17-de66-a30b34331e0f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  Artist                Title  \\\n0   FFDP                Ashes   \n1   FFDP  The_Way_Of_The_Fist   \n\n                                              Lyrics  \\\n0     Right Hate, hate, hate! Bring it!  You don'...   \n1     Break this shit down! Zoltan, open the sky!...   \n\n                                      Cleaned_Lyrics  \n0  [right, hate, hate, hate, bring, dont, underst...  \n1  [break, shit, zoltan, open, sky, want, got, ev...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Artist</th>\n      <th>Title</th>\n      <th>Lyrics</th>\n      <th>Cleaned_Lyrics</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>FFDP</td>\n      <td>Ashes</td>\n      <td>Right Hate, hate, hate! Bring it!  You don'...</td>\n      <td>[right, hate, hate, hate, bring, dont, underst...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>FFDP</td>\n      <td>The_Way_Of_The_Fist</td>\n      <td>Break this shit down! Zoltan, open the sky!...</td>\n      <td>[break, shit, zoltan, open, sky, want, got, ev...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffdp_lyrics_df['Cleaned_Lyrics'] = ffdp_lyrics_df.loc[:,'Lyrics'].map(text_prep)\n",
    "ffdp_lyrics_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "MkR56JnxKvYA",
   "metadata": {
    "id": "MkR56JnxKvYA",
    "outputId": "7d5b255b-de56-47bc-8ce1-a3fa7e7e42ff",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         Artist       Title  \\\n0  OfficialRezz        Lost   \n1  OfficialRezz  Melancholy   \n\n                                              Lyrics  \\\n0     What a beautiful world to be anything but a...   \n1     All these thoughts are running through my h...   \n\n                                      Cleaned_Lyrics  \n0  [beautiful, world, anything, alone, cant, find...  \n1  [thoughts, running, head, cant, control, takin...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Artist</th>\n      <th>Title</th>\n      <th>Lyrics</th>\n      <th>Cleaned_Lyrics</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>OfficialRezz</td>\n      <td>Lost</td>\n      <td>What a beautiful world to be anything but a...</td>\n      <td>[beautiful, world, anything, alone, cant, find...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>OfficialRezz</td>\n      <td>Melancholy</td>\n      <td>All these thoughts are running through my h...</td>\n      <td>[thoughts, running, head, cant, control, takin...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rezz_lyrics_df['Cleaned_Lyrics'] = rezz_lyrics_df.loc[:,'Lyrics'].map(text_prep)\n",
    "rezz_lyrics_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ouP7-rYuUAZj",
   "metadata": {
    "id": "ouP7-rYuUAZj",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Empty Row Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "TggxK9hsUAZj",
   "metadata": {
    "id": "TggxK9hsUAZj",
    "outputId": "36a131ee-a68b-4d00-ebf6-915c40928ab4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  Artist                                        Description  \\\n0   FFDP  A pup who loves to boop the snoot! | 27 | Pans...   \n1   FFDP   Attorney. Virginian. History and Political Nerd.   \n2   FFDP                                          SJB\\ngr.9   \n3   FFDP  Inbox let have some fun 👇👇 can't wait to get y...   \n4   FFDP  I’m only interested in what's real. Real peopl...   \n\n                                        Cleaned_Desc  Cleaned_Len  \n0  [pup, loves, boop, snoot, 27, pansexual, domal...           15  \n1    [attorney, virginian, history, political, nerd]            5  \n2                                         [sjb, gr9]            2  \n3  [inbox, let, fun, 👇👇, cant, wait, get, message...           11  \n4  [i’m, interested, whats, real, real, people, r...           10  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Artist</th>\n      <th>Description</th>\n      <th>Cleaned_Desc</th>\n      <th>Cleaned_Len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>FFDP</td>\n      <td>A pup who loves to boop the snoot! | 27 | Pans...</td>\n      <td>[pup, loves, boop, snoot, 27, pansexual, domal...</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>FFDP</td>\n      <td>Attorney. Virginian. History and Political Nerd.</td>\n      <td>[attorney, virginian, history, political, nerd]</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>FFDP</td>\n      <td>SJB\\ngr.9</td>\n      <td>[sjb, gr9]</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>FFDP</td>\n      <td>Inbox let have some fun 👇👇 can't wait to get y...</td>\n      <td>[inbox, let, fun, 👇👇, cant, wait, get, message...</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>FFDP</td>\n      <td>I’m only interested in what's real. Real peopl...</td>\n      <td>[i’m, interested, whats, real, real, people, r...</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a column which holds count of tokens for description\n",
    "ffdp_followers_df['Cleaned_Len'] = ffdp_followers_df['Cleaned_Desc'].map(len)\n",
    "ffdp_lyrics_df['Cleaned_Len'] = ffdp_lyrics_df['Cleaned_Lyrics'].map(len)\n",
    "\n",
    "rezz_followers_df['Cleaned_Len'] = rezz_followers_df['Cleaned_Desc'].map(len)\n",
    "rezz_lyrics_df['Cleaned_Len'] = rezz_lyrics_df['Cleaned_Lyrics'].map(len)\n",
    "\n",
    "ffdp_followers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e9BLb0wUAZk",
   "metadata": {
    "id": "3e9BLb0wUAZk",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def no_data_row_deleter(df):\n",
    "    b4 = df.shape[0]\n",
    "    df = df.loc[df['Cleaned_Len'] != 0]\n",
    "    after = df.shape[0]\n",
    "    dif = b4 - after\n",
    "    print('--'*2,f'Dropped {dif} rows','--'*2)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "NROJKOkJUAZk",
   "metadata": {
    "id": "NROJKOkJUAZk",
    "outputId": "98df6812-9cd4-40fd-d6d5-7896bee3c7cd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Dropped 763 rows ----\n"
     ]
    }
   ],
   "source": [
    "ffdp_followers_df = no_data_row_deleter(ffdp_followers_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9tKA3DgLUAZk",
   "metadata": {
    "id": "9tKA3DgLUAZk",
    "outputId": "ba8ab465-0d94-408c-9146-4d6de27b93ea",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Dropped 620 rows ----\n"
     ]
    }
   ],
   "source": [
    "rezz_followers_df = no_data_row_deleter(rezz_followers_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DdcXPwHAUAZk",
   "metadata": {
    "id": "DdcXPwHAUAZk",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Rezz has one song where the only word spoken is the stopword \"I\", in which AZLyrics has the lyrics as \"I [repeated]\" and nothing more.  Post data cleaning, the cleaned lyrics from the song is \"[repeated]\" as shown in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "JvRNVCUXUAZk",
   "metadata": {
    "id": "JvRNVCUXUAZk",
    "outputId": "945b9fd1-66f1-442e-fa30-ed8e2425e698",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Artist                OfficialRezz\nTitle                            I\nLyrics               I [repeated] \nCleaned_Lyrics          [repeated]\nCleaned_Len                      1\nName: 19, dtype: object"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rezz_lyrics_df.iloc[19,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ay9VeN51UAZk",
   "metadata": {
    "id": "ay9VeN51UAZk",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Because \"repeated\" is not apart of the song lyrics, the row is deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "i1Qe096PUAZk",
   "metadata": {
    "id": "i1Qe096PUAZk",
    "outputId": "aa6ac447-8b6e-413f-ce71-311a7fb5246a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(19, 5)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rezz_lyrics_df = rezz_lyrics_df.iloc[0:19,:]\n",
    "rezz_lyrics_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pJlUuIA3UAZl",
   "metadata": {
    "id": "pJlUuIA3UAZl",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Basic Descriptive Statistics\n",
    "\n",
    "Call your `descriptive_stats` function on both yo›ur lyrics data and your twitter data and for both artists (four total calls)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "x2ediX1-UAZl",
   "metadata": {
    "id": "x2ediX1-UAZl",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "STUDENT NOTE:  Some descriptions only contain stopwords, thus will be pointless.  Let's see how many rows are now empty due to stopword removal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "n0_VIOQGUAZl",
   "metadata": {
    "id": "n0_VIOQGUAZl",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Corpus Build & Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "iFml_j0_UAZl",
   "metadata": {
    "id": "iFml_j0_UAZl",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def desc_stats_2_DF(stats, stats_of):\n",
    "    df = pd.DataFrame({'stats_of':[stats_of],\n",
    "                       'num_tokens':[stats[0]],\n",
    "                       'num_unique_tokens':[stats[1]],\n",
    "                       'lexical_diversity':[stats[2]],\n",
    "                       'num_characters':[stats[3]]})\n",
    "    return df\n",
    "\n",
    "def df_corpus_maker(df, corpus_column):\n",
    "    corpus = []\n",
    "    for ix, row in df.iterrows():\n",
    "        corpus.extend(row[corpus_column])\n",
    "\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HnfGc8dRUAZn",
   "metadata": {
    "id": "HnfGc8dRUAZn",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### FFDP Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FI-DxhGMUAZn",
   "metadata": {
    "id": "FI-DxhGMUAZn",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### FFDP Twitter Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ywik0xwaUAZn",
   "metadata": {
    "id": "ywik0xwaUAZn",
    "outputId": "1725a198-cd88-4297-9f7d-07083184a2ea",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 439951 tokens in the data.\n",
      "There are 91559 unique tokens in the data.\n",
      "There are 2524753 characters in the data.\n",
      "The lexical diversity is 0.208 in the data.\n",
      "************************ \n",
      " -----TOP 5 TOKENS-----\n",
      "    keys  values\n",
      "0   love    5133\n",
      "1     im    4814\n",
      "2  music    4045\n",
      "3   life    2980\n",
      "4  metal    2480\n"
     ]
    },
    {
     "data": {
      "text/plain": "       stats_of  num_tokens  num_unique_tokens  lexical_diversity  \\\n0  ffdp_twitter      439951              91559           0.208112   \n\n   num_characters  \n0         2524753  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>stats_of</th>\n      <th>num_tokens</th>\n      <th>num_unique_tokens</th>\n      <th>lexical_diversity</th>\n      <th>num_characters</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ffdp_twitter</td>\n      <td>439951</td>\n      <td>91559</td>\n      <td>0.208112</td>\n      <td>2524753</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffdp_twitter_corpus = df_corpus_maker(ffdp_followers_df, 'Cleaned_Desc')\n",
    "ffdp_twitter_stats = descriptive_stats(ffdp_twitter_corpus, top_tokens=True, verbose=True)\n",
    "ffdp_twitter_stats = desc_stats_2_DF(ffdp_twitter_stats, 'ffdp_twitter')\n",
    "ffdp_twitter_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Z35cyT1RUAZn",
   "metadata": {
    "id": "Z35cyT1RUAZn",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### FFDP Lyrics Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "IQjn7FFRUAZo",
   "metadata": {
    "id": "IQjn7FFRUAZo",
    "outputId": "a4b3af5f-2f36-44ef-f444-47b94c2a187d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2312 tokens in the data.\n",
      "There are 684 unique tokens in the data.\n",
      "There are 11725 characters in the data.\n",
      "The lexical diversity is 0.296 in the data.\n",
      "************************ \n",
      " -----TOP 5 TOKENS-----\n",
      "    keys  values\n",
      "0     im      56\n",
      "1  never      53\n",
      "2   cant      44\n",
      "3    one      41\n",
      "4   dont      38\n"
     ]
    },
    {
     "data": {
      "text/plain": "      stats_of  num_tokens  num_unique_tokens  lexical_diversity  \\\n0  ffdp_lyrics        2312                684           0.295848   \n\n   num_characters  \n0           11725  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>stats_of</th>\n      <th>num_tokens</th>\n      <th>num_unique_tokens</th>\n      <th>lexical_diversity</th>\n      <th>num_characters</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ffdp_lyrics</td>\n      <td>2312</td>\n      <td>684</td>\n      <td>0.295848</td>\n      <td>11725</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffdp_lyrics_corpus = df_corpus_maker(ffdp_lyrics_df, 'Cleaned_Lyrics')\n",
    "ffdp_lyrics_stats = descriptive_stats(ffdp_lyrics_corpus, top_tokens=True, verbose=True)\n",
    "ffdp_lyrics_stats = desc_stats_2_DF(ffdp_lyrics_stats, 'ffdp_lyrics')\n",
    "ffdp_lyrics_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lMWTV0ZkUAZo",
   "metadata": {
    "id": "lMWTV0ZkUAZo",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Rezz Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mH2g9e6KUAZo",
   "metadata": {
    "id": "mH2g9e6KUAZo",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Rezz Twitter Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5wDhMd2hUAZo",
   "metadata": {
    "id": "5wDhMd2hUAZo",
    "outputId": "319b42da-e315-42fc-8fd4-1defb1b6ebf3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 464405 tokens in the data.\n",
      "There are 107752 unique tokens in the data.\n",
      "There are 2673509 characters in the data.\n",
      "The lexical diversity is 0.232 in the data.\n",
      "************************ \n",
      " -----TOP 5 TOKENS-----\n",
      "    keys  values\n",
      "0  music    5660\n",
      "1      •    4518\n",
      "2   love    2762\n",
      "3   life    2347\n",
      "4     im    2308\n"
     ]
    },
    {
     "data": {
      "text/plain": "       stats_of  num_tokens  num_unique_tokens  lexical_diversity  \\\n0  rezz_twitter      464405             107752           0.232022   \n\n   num_characters  \n0         2673509  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>stats_of</th>\n      <th>num_tokens</th>\n      <th>num_unique_tokens</th>\n      <th>lexical_diversity</th>\n      <th>num_characters</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>rezz_twitter</td>\n      <td>464405</td>\n      <td>107752</td>\n      <td>0.232022</td>\n      <td>2673509</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rezz_twitter_corpus = df_corpus_maker(rezz_followers_df, 'Cleaned_Desc')\n",
    "rezz_twitter_stats = descriptive_stats(rezz_twitter_corpus, top_tokens=True, verbose=True)\n",
    "rezz_twitter_stats = desc_stats_2_DF(rezz_twitter_stats, 'rezz_twitter')\n",
    "rezz_twitter_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KltDYi6zUAZo",
   "metadata": {
    "id": "KltDYi6zUAZo",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Rezz Lyrics Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "TFZGdbLxUAZo",
   "metadata": {
    "id": "TFZGdbLxUAZo",
    "outputId": "87fd7244-0595-454e-e469-6045fbc573a3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1304 tokens in the data.\n",
      "There are 362 unique tokens in the data.\n",
      "There are 6305 characters in the data.\n",
      "The lexical diversity is 0.278 in the data.\n",
      "************************ \n",
      " -----TOP 5 TOKENS-----\n",
      "   keys  values\n",
      "0  head      43\n",
      "1  take      38\n",
      "2  time      36\n",
      "3  lost      35\n",
      "4    oh      34\n"
     ]
    },
    {
     "data": {
      "text/plain": "      stats_of  num_tokens  num_unique_tokens  lexical_diversity  \\\n0  rezz_lyrics        1304                362           0.277607   \n\n   num_characters  \n0            6305  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>stats_of</th>\n      <th>num_tokens</th>\n      <th>num_unique_tokens</th>\n      <th>lexical_diversity</th>\n      <th>num_characters</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>rezz_lyrics</td>\n      <td>1304</td>\n      <td>362</td>\n      <td>0.277607</td>\n      <td>6305</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rezz_lyrics_corpus = df_corpus_maker(rezz_lyrics_df, 'Cleaned_Lyrics')\n",
    "rezz_lyrics_stats = descriptive_stats(rezz_lyrics_corpus, top_tokens=True, verbose=True)\n",
    "rezz_lyrics_stats = desc_stats_2_DF(rezz_lyrics_stats, 'rezz_lyrics')\n",
    "rezz_lyrics_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zX2b-RYOUAZo",
   "metadata": {
    "id": "zX2b-RYOUAZo",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Stats Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "55Us0hNDUAZo",
   "metadata": {
    "id": "55Us0hNDUAZo",
    "outputId": "b0b56ec3-e9d6-41ee-d111-e6119439d83a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       stats_of  num_tokens  num_unique_tokens  lexical_diversity  \\\n0  ffdp_twitter      439951              91559           0.208112   \n0   ffdp_lyrics        2312                684           0.295848   \n0  rezz_twitter      464405             107752           0.232022   \n0   rezz_lyrics        1304                362           0.277607   \n\n   num_characters  \n0         2524753  \n0           11725  \n0         2673509  \n0            6305  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>stats_of</th>\n      <th>num_tokens</th>\n      <th>num_unique_tokens</th>\n      <th>lexical_diversity</th>\n      <th>num_characters</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ffdp_twitter</td>\n      <td>439951</td>\n      <td>91559</td>\n      <td>0.208112</td>\n      <td>2524753</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>ffdp_lyrics</td>\n      <td>2312</td>\n      <td>684</td>\n      <td>0.295848</td>\n      <td>11725</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>rezz_twitter</td>\n      <td>464405</td>\n      <td>107752</td>\n      <td>0.232022</td>\n      <td>2673509</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>rezz_lyrics</td>\n      <td>1304</td>\n      <td>362</td>\n      <td>0.277607</td>\n      <td>6305</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([ffdp_twitter_stats,\n",
    "           ffdp_lyrics_stats,\n",
    "           rezz_twitter_stats,\n",
    "           rezz_lyrics_stats])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oQEk0CtVUAZp",
   "metadata": {
    "id": "oQEk0CtVUAZp",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Q: How do you think the \"top 5 words\" would be different if we left stopwords in the data?\n",
    "\n",
    "A: By the looks of how many rows were dropped due to the removal of stop words, totally different. Just like this week's De La Soul reference to the song <i>Me, Myself, and I</i>, Rezz too has a song in which the stop word \"I\" is repeated numerous times throughout the five minute song.  Thus, Rezz's song \"I\" most likely did not contribute to the lyrics corpus.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Q: What were your prior beliefs about the lexical diversity between the artists? Does the difference (or lack thereof) in lexical diversity between the artists conform to your prior beliefs? \n",
    "\n",
    "A: Due to the nature of both artists, I assumed that FFDP would have a far greater percentage of lexical diversity (even with just 20 songs per artist).  This is due to FFDP being a Metal band in which most of their songs have a full on story and Rezz being an Electronic music producer with most of her songs (like most electronic music) have little to no lyrics and even then, the lyrics are most of the time repeated over and over.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CLg7ZNpwUAZp",
   "metadata": {
    "id": "CLg7ZNpwUAZp",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "## Specialty Statistics\n",
    "\n",
    "The descriptive statistics we have calculated are quite generic. You will now calculate a handful of statistics tailored to these data.\n",
    "\n",
    "1. Ten most common emojis by artist in the twitter descriptions.\n",
    "1. Ten most common hashtags by artist in the twitter descriptions.\n",
    "1. Five most common words in song titles by artist. \n",
    "1. For each artist, a histogram of song lengths (in terms of number of tokens) \n",
    "\n",
    "We can use the `emoji` library to help us identify emojis and you have been given a function to help you.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "FiOp71lhUAZp",
   "metadata": {
    "id": "FiOp71lhUAZp",
    "outputId": "e45fae75-c1e4-418f-d3b4-6dd9a6f7ba62",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "2nd str Not an Emoji!",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[0;32mIn [29]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m str2 \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m:-)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m emoji\u001B[38;5;241m.\u001B[39mis_emoji(str1), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m1st str Not an Emoji!\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m emoji\u001B[38;5;241m.\u001B[39mis_emoji(str2), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m2nd str Not an Emoji!\u001B[39m\u001B[38;5;124m'\u001B[39m\n",
      "\u001B[0;31mAssertionError\u001B[0m: 2nd str Not an Emoji!"
     ]
    }
   ],
   "source": [
    "str1 = \"❤️\"\n",
    "str2 = \":-)\"\n",
    "\n",
    "assert emoji.is_emoji(str1), '1st str Not an Emoji!'\n",
    "assert emoji.is_emoji(str2), '2nd str Not an Emoji!'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NBI8zNs1UAZp",
   "metadata": {
    "id": "NBI8zNs1UAZp",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Emojis 😁\n",
    "\n",
    "What are the ten most common emojis by artist in the twitter descriptions? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZrxdM6jKUAZq",
   "metadata": {
    "id": "ZrxdM6jKUAZq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def top_10_emojis(corpus):\n",
    "    list_of_emojis = []\n",
    "    for desc in corpus:\n",
    "        emoji_list = emoji.emoji_list(desc)\n",
    "        list_of_emojis.extend(emoji_list)\n",
    "\n",
    "    df = pd.DataFrame(list_of_emojis)\n",
    "\n",
    "    # return top 10 emojis\n",
    "    return df['emoji'].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PI9sUVJcUAZq",
   "metadata": {
    "id": "PI9sUVJcUAZq",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### FFDP Emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22Qh4CqUAZq",
   "metadata": {
    "id": "c22Qh4CqUAZq",
    "outputId": "659a9a9d-8ab8-49a9-b1f2-f2ecc8844722",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "top_10_emojis(ffdp_twitter_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pkwdx2GrUAZq",
   "metadata": {
    "id": "pkwdx2GrUAZq",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Rezz Emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZAZgv4q3UAZq",
   "metadata": {
    "id": "ZAZgv4q3UAZq",
    "outputId": "13421c60-d3e0-46af-b654-c1191aa00f5f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "top_10_emojis(rezz_twitter_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5MGRp9ObUAZq",
   "metadata": {
    "id": "5MGRp9ObUAZq",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Hashtags\n",
    "\n",
    "What are the ten most common hashtags by artist in the twitter descriptions? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EUR9GvjWUAZr",
   "metadata": {
    "id": "EUR9GvjWUAZr",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def hash_tag_counter(corpus):\n",
    "    hash_tags = []\n",
    "    for desc in corpus:\n",
    "        if desc[0] == '#':\n",
    "            hash_tags.append(desc)\n",
    "\n",
    "    return pd.Series(hash_tags).value_counts()[:10]\n",
    "    \n",
    "def text_prep_w_hashtags(text):\n",
    "    punctuation = set(string.punctuation) # speeds up comparison\n",
    "    punctuation.remove('#')  # to capture hashtags in description\n",
    "    # remove punctuation chars then tokenize string\n",
    "    text = ''.join(char for char in text if char not in punctuation).split()\n",
    "    # lowercase all\n",
    "    text = [word.lower() for word in text]\n",
    "    # remove stop words\n",
    "    text = [word for word in text if word not in sw]\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8etA7djAUAZr",
   "metadata": {
    "id": "8etA7djAUAZr",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ffdp_followers_df['clean_w_hashtags'] = ffdp_followers_df.loc[:,'Description'].map(text_prep_w_hashtags)\n",
    "rezz_followers_df['clean_w_hashtags'] = rezz_followers_df.loc[:,'Description'].map(text_prep_w_hashtags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KZ4DCe39UAZr",
   "metadata": {
    "id": "KZ4DCe39UAZr",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### FFDP Hash Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "O4TJhKlnUAZr",
   "metadata": {
    "id": "O4TJhKlnUAZr",
    "outputId": "41d63f17-3469-4780-bbff-65fe926a8690",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ffdp_hash_corpus = df_corpus_maker(ffdp_followers_df, 'clean_w_hashtags')\n",
    "hash_tag_counter(ffdp_hash_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23qXtD9cUAZr",
   "metadata": {
    "id": "23qXtD9cUAZr",
    "outputId": "6ff515e1-745d-4ce0-ff47-cb81f7dc999c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hash_tag_counter(ffdp_hash_corpus).plot(kind='barh').invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8MgWEKC2UAZr",
   "metadata": {
    "id": "8MgWEKC2UAZr",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Rezz Hash Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yHo4_9WdUAZr",
   "metadata": {
    "id": "yHo4_9WdUAZr",
    "outputId": "bbac8108-dde2-4356-90e6-d55acbc07c76",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rezz_hash_corpus = df_corpus_maker(rezz_followers_df, 'clean_w_hashtags')\n",
    "hash_tag_counter(rezz_hash_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XPG7EdAkUAZr",
   "metadata": {
    "id": "XPG7EdAkUAZr",
    "outputId": "9c6bd325-97d0-45ac-edc9-1fe2ad38f826",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hash_tag_counter(rezz_hash_corpus).plot(kind='barh').invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vQZamX2uUAZr",
   "metadata": {
    "id": "vQZamX2uUAZr",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Song Titles\n",
    "\n",
    "What are the five most common words in song titles by artist? The song titles should be on the first line of the lyrics pages, so if you have kept the raw file contents around, you will not need to re-read the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "azKHfoWdUAZs",
   "metadata": {
    "id": "azKHfoWdUAZs",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def title_word_counter(series_):\n",
    "    # all titles have '_' as a whitespace holder\n",
    "    series_ = series_.str.split('_')\n",
    "\n",
    "    title_corpus = []\n",
    "    for row in series_:\n",
    "        title_corpus.extend(row)\n",
    "\n",
    "    return pd.Series(title_corpus).value_counts()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exyF8Kr7UAZs",
   "metadata": {
    "id": "exyF8Kr7UAZs",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### FFDP Song Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nAIdZ2phUAZs",
   "metadata": {
    "id": "nAIdZ2phUAZs",
    "outputId": "36156edb-48c3-4c8e-9900-8f77c7872589",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "title_word_counter(ffdp_lyrics_df['Title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Be4-ryITLj7V",
   "metadata": {
    "id": "Be4-ryITLj7V",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Rezz Song Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "U2lFmINyKvYH",
   "metadata": {
    "id": "U2lFmINyKvYH",
    "outputId": "8e8186ad-2302-40fb-c0f5-f4fbd38c3569",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "title_word_counter(rezz_lyrics_df['Title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd4fd71",
   "metadata": {
    "id": "5dd4fd71",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Song Lengths\n",
    "\n",
    "For each artist, a histogram of song lengths (in terms of number of tokens). If you put the song lengths in a data frame with an artist column, matplotlib will make the plotting quite easy. An example is given to help you out. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oTnIcTEhKvYH",
   "metadata": {
    "id": "oTnIcTEhKvYH",
    "outputId": "49bc79c8-972a-4f7e-ccdf-84b440939a90",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# count length of tokens in description\n",
    "ffdp_lyrics_df['Dirty_Len'] = ffdp_lyrics_df.loc[:,'Lyrics'].apply(len)\n",
    "rezz_lyrics_df['Dirty_Len'] = rezz_lyrics_df.loc[:,'Lyrics'].apply(len)\n",
    "\n",
    "lyrics_concat = pd.concat([ffdp_lyrics_df[['Artist','Dirty_Len']],\n",
    "                           rezz_lyrics_df[['Artist','Dirty_Len']]])\n",
    "lyrics_concat.groupby('Artist')['Dirty_Len'].plot(kind=\"hist\",density=True,alpha=0.5,legend=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fde9ebb",
   "metadata": {
    "id": "8fde9ebb",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Since the lyrics may be stored with carriage returns or tabs, it may be useful to have a function that can collapse whitespace, using regular expressions, and be used for splitting. \n",
    "\n",
    "Q: What does the regular expression `'\\s+'` match on? \n",
    "\n",
    "A: \"Matches Unicode whitespace characters (which includes [ \\t\\n\\r\\f\\v]\"\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}